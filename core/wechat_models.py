"""
WeChatå…³ç³»å›¾è°±æ•°æ®æ¨¡å‹
ä¸“é—¨ç”¨äºå¤„ç†å¾®ä¿¡èŠå¤©æ•°æ®çš„ç»“æ„åŒ–æ¨¡å‹
"""

from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any, Union
from datetime import datetime
from enum import Enum


class EpisodeType(str, Enum):
    """Episodeç±»å‹æšä¸¾"""
    PERSON_IDENTITY = "person_identity"      # äººå‘˜èº«ä»½
    GROUP_CONTEXT = "group_context"          # ç¾¤ç»„/ä¸Šä¸‹æ–‡
    PERSON_RELATIONSHIP = "person_relationship"  # äººé™…å…³ç³»
    GROUP_MEMBERSHIP = "group_membership"     # ç¾¤ç»„æˆå‘˜å…³ç³»
    ACTIVITY_PARTICIPATION = "activity_participation"  # æ´»åŠ¨å‚ä¸
    SOCIAL_SCENARIO = "social_scenario"       # ç»¼åˆç¤¾äº¤åœºæ™¯


class RelationshipType(str, Enum):
    """å…³ç³»ç±»å‹æšä¸¾"""
    COLLEAGUE = "colleague"           # åŒäº‹
    PROJECT_COLLABORATOR = "project_collaborator"  # é¡¹ç›®åˆä½œè€…
    FRIEND = "friend"                # æœ‹å‹
    FAMILY = "family"               # å®¶äºº
    CLASSMATE = "classmate"         # åŒå­¦
    UNKNOWN = "unknown"             # æœªçŸ¥å…³ç³»


class WeChatUser(BaseModel):
    """å¾®ä¿¡ç”¨æˆ·æ¨¡å‹"""
    original_name: str = Field(..., description="åŸå§‹å¾®ä¿¡æ˜µç§°")
    cleaned_name: str = Field(..., description="æ¸…æ´—åçš„æ ‡å‡†åŒ–æ˜µç§°")
    wechat_id: Optional[str] = Field(None, description="å¾®ä¿¡IDï¼ˆå¦‚æœå¯è·å–ï¼‰")
    user_type: str = Field(default="user", description="ç”¨æˆ·ç±»å‹")
    
    @validator('cleaned_name')
    def validate_cleaned_name(cls, v):
        """éªŒè¯æ¸…æ´—åçš„æ˜µç§°"""
        if not v or len(v.strip()) == 0:
            raise ValueError("æ¸…æ´—åçš„æ˜µç§°ä¸èƒ½ä¸ºç©º")
        return v.strip()


class WeChatGroup(BaseModel):
    """å¾®ä¿¡ç¾¤ç»„æ¨¡å‹"""
    group_name: str = Field(..., description="ç¾¤ç»„åç§°")
    group_type: str = Field(..., description="ç¾¤ç»„ç±»å‹ï¼Œå¦‚'å·¥ä½œç¾¤ç»„'ã€'æœ‹å‹ç¾¤'ç­‰")
    description: Optional[str] = Field(None, description="ç¾¤ç»„æè¿°")
    members: List[WeChatUser] = Field(default_factory=list, description="ç¾¤ç»„æˆå‘˜åˆ—è¡¨")
    topic: Optional[str] = Field(None, description="ç¾¤ç»„ä¸»é¢˜")
    
    @validator('group_name')
    def validate_group_name(cls, v):
        """éªŒè¯ç¾¤ç»„åç§°"""
        if not v or len(v.strip()) == 0:
            raise ValueError("ç¾¤ç»„åç§°ä¸èƒ½ä¸ºç©º")
        return v.strip()


class WeChatRelationship(BaseModel):
    """å¾®ä¿¡å…³ç³»æ¨¡å‹"""
    person_a: str = Field(..., description="å…³ç³»ä¸­çš„ç¬¬ä¸€äººï¼ˆæ¸…æ´—åæ˜µç§°ï¼‰")
    person_b: str = Field(..., description="å…³ç³»ä¸­çš„ç¬¬äºŒäººï¼ˆæ¸…æ´—åæ˜µç§°ï¼‰")
    relationship_type: RelationshipType = Field(..., description="å…³ç³»ç±»å‹")
    context: Optional[str] = Field(None, description="å…³ç³»ä¸Šä¸‹æ–‡ï¼Œå¦‚ç¾¤ç»„åç§°")
    confidence: float = Field(default=0.8, ge=0.0, le=1.0, description="å…³ç³»ç½®ä¿¡åº¦")
    
    @validator('person_a', 'person_b')
    def validate_person_names(cls, v):
        """éªŒè¯äººå‘˜åç§°"""
        if not v or len(v.strip()) == 0:
            raise ValueError("äººå‘˜åç§°ä¸èƒ½ä¸ºç©º")
        return v.strip()


class WeChatActivity(BaseModel):
    """å¾®ä¿¡æ´»åŠ¨æ¨¡å‹"""
    activity_date: datetime = Field(..., description="æ´»åŠ¨æ—¥æœŸ")
    participant: str = Field(..., description="å‚ä¸è€…ï¼ˆæ¸…æ´—åæ˜µç§°ï¼‰")
    group_context: str = Field(..., description="æ´»åŠ¨ä¸Šä¸‹æ–‡ï¼ˆç¾¤ç»„åç§°ï¼‰")
    activity_type: str = Field(default="group_chat", description="æ´»åŠ¨ç±»å‹")
    
    @validator('participant', 'group_context')
    def validate_activity_fields(cls, v):
        """éªŒè¯æ´»åŠ¨å­—æ®µ"""
        if not v or len(v.strip()) == 0:
            raise ValueError("æ´»åŠ¨å­—æ®µä¸èƒ½ä¸ºç©º")
        return v.strip()


class WeChatEpisode(BaseModel):
    """å¾®ä¿¡Episodeæ¨¡å‹ - è½¬æ¢ä¸ºGraphitiå¯ç†è§£çš„æ–‡æœ¬ç‰‡æ®µ"""
    episode_id: str = Field(..., description="Episodeå”¯ä¸€æ ‡è¯†")
    episode_type: EpisodeType = Field(..., description="Episodeç±»å‹")
    content: str = Field(..., description="Episodeæ–‡æœ¬å†…å®¹")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Episodeå…ƒæ•°æ®")
    source_file: str = Field(..., description="æ¥æºæ–‡ä»¶è·¯å¾„")
    created_at: datetime = Field(default_factory=datetime.now, description="åˆ›å»ºæ—¶é—´")
    
    @validator('content')
    def validate_content(cls, v):
        """éªŒè¯Episodeå†…å®¹"""
        if not v or len(v.strip()) == 0:
            raise ValueError("Episodeå†…å®¹ä¸èƒ½ä¸ºç©º")
        return v.strip()
    
    @validator('episode_id')
    def validate_episode_id(cls, v):
        """éªŒè¯Episode ID"""
        if not v or len(v.strip()) == 0:
            raise ValueError("Episode IDä¸èƒ½ä¸ºç©º")
        return v.strip()


class WeChatChatMessage(BaseModel):
    """å¾®ä¿¡èŠå¤©æ¶ˆæ¯åŸå§‹æ¨¡å‹"""
    sender: str = Field(..., description="å‘é€è€…åŸå§‹æ˜µç§°")
    message: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    timestamp: datetime = Field(..., description="æ¶ˆæ¯æ—¶é—´æˆ³")
    message_type: str = Field(default="text", description="æ¶ˆæ¯ç±»å‹")
    
    @validator('sender')
    def validate_sender(cls, v):
        """éªŒè¯å‘é€è€…"""
        if not v or len(v.strip()) == 0:
            raise ValueError("å‘é€è€…ä¸èƒ½ä¸ºç©º")
        return v.strip()


class WeChatChatFile(BaseModel):
    """å¾®ä¿¡èŠå¤©æ–‡ä»¶æ¨¡å‹"""
    file_path: str = Field(..., description="æ–‡ä»¶è·¯å¾„")
    group_name: str = Field(..., description="ç¾¤ç»„åç§°")
    chat_date: datetime = Field(..., description="èŠå¤©æ—¥æœŸ")
    messages: List[WeChatChatMessage] = Field(default_factory=list, description="èŠå¤©æ¶ˆæ¯åˆ—è¡¨")
    processed: bool = Field(default=False, description="æ˜¯å¦å·²å¤„ç†")
    
    @validator('file_path')
    def validate_file_path(cls, v):
        """éªŒè¯æ–‡ä»¶è·¯å¾„"""
        if not v or len(v.strip()) == 0:
            raise ValueError("æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return v.strip()


class WeChatDataProcessor(BaseModel):
    """å¾®ä¿¡æ•°æ®å¤„ç†å™¨é…ç½®"""
    input_directory: str = Field(..., description="è¾“å…¥ç›®å½•è·¯å¾„")
    output_directory: str = Field(..., description="è¾“å‡ºç›®å½•è·¯å¾„")
    name_cleaning_rules: Dict[str, str] = Field(default_factory=dict, description="å§“åæ¸…æ´—è§„åˆ™")
    deduplication_enabled: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨å»é‡")
    activity_deduplication_enabled: bool = Field(default=False, description="æ´»åŠ¨æ˜¯å¦å»é‡")
    
    @validator('input_directory', 'output_directory')
    def validate_directories(cls, v):
        """éªŒè¯ç›®å½•è·¯å¾„"""
        if not v or len(v.strip()) == 0:
            raise ValueError("ç›®å½•è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return v.strip()


class EpisodeGenerationResult(BaseModel):
    """Episodeç”Ÿæˆç»“æœæ¨¡å‹"""
    success: bool = Field(..., description="ç”Ÿæˆæ˜¯å¦æˆåŠŸ")
    total_episodes: int = Field(default=0, description="ç”Ÿæˆçš„Episodeæ€»æ•°")
    episodes_by_type: Dict[str, int] = Field(default_factory=dict, description="æŒ‰ç±»å‹ç»Ÿè®¡çš„Episodeæ•°é‡")
    processed_files: List[str] = Field(default_factory=list, description="å·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨")
    errors: List[str] = Field(default_factory=list, description="é”™è¯¯ä¿¡æ¯åˆ—è¡¨")
    processing_time_seconds: float = Field(default=0.0, description="å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰")


class QueryAnalysisResult(BaseModel):
    """æŸ¥è¯¢åˆ†æç»“æœæ¨¡å‹"""
    query_type: str = Field(..., description="æŸ¥è¯¢ç±»å‹")
    key_entities: Dict[str, List[str]] = Field(default_factory=dict, description="å…³é”®å®ä½“")
    core_intent: str = Field(..., description="æ ¸å¿ƒæ„å›¾")
    search_keywords: List[str] = Field(default_factory=list, description="æœç´¢å…³é”®è¯")
    confidence: float = Field(default=0.8, ge=0.0, le=1.0, description="åˆ†æç½®ä¿¡åº¦")


class RelationshipSearchRequest(BaseModel):
    """å…³ç³»æœç´¢è¯·æ±‚æ¨¡å‹"""
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢")
    search_type: str = Field(default="relationship", description="æœç´¢ç±»å‹")
    max_results: int = Field(default=5, ge=1, le=20, description="æœ€å¤§ç»“æœæ•°")
    confidence_threshold: float = Field(default=0.7, ge=0.0, le=1.0, description="ç½®ä¿¡åº¦é˜ˆå€¼")
    
    @validator('query')
    def validate_query(cls, v):
        """éªŒè¯æŸ¥è¯¢å†…å®¹"""
        if not v or len(v.strip()) == 0:
            raise ValueError("æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º")
        return v.strip()


class RelationshipSearchResult(BaseModel):
    """å…³ç³»æœç´¢ç»“æœæ¨¡å‹"""
    success: bool = Field(..., description="æœç´¢æ˜¯å¦æˆåŠŸ")
    query_analysis: Optional[QueryAnalysisResult] = Field(None, description="æŸ¥è¯¢åˆ†æç»“æœ")
    episodes: List[str] = Field(default_factory=list, description="ç›¸å…³Episodeåˆ—è¡¨")
    formatted_answer: str = Field(default="", description="æ ¼å¼åŒ–çš„ç­”æ¡ˆ")
    processing_time_ms: float = Field(default=0.0, description="å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")


# å·¥å…·å‡½æ•°
def clean_wechat_name(original_name: str) -> str:
    """
    æ¸…æ´—å¾®ä¿¡æ˜µç§°çš„æ ‡å‡†åŒ–å‡½æ•°
    
    Args:
        original_name: åŸå§‹å¾®ä¿¡æ˜µç§°
        
    Returns:
        str: æ¸…æ´—åçš„æ˜µç§°
    """
    if not original_name:
        return "æœªçŸ¥ç”¨æˆ·"
    
    # ç§»é™¤å¸¸è§çš„è£…é¥°æ€§å­—ç¬¦
    cleaned = original_name.strip()
    
    # ç§»é™¤emojiå’Œç‰¹æ®Šç¬¦å·çš„åŸºæœ¬è§„åˆ™
    import re
    
    # ç§»é™¤emojiè¡¨æƒ…
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags (iOS)
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE
    )
    cleaned = emoji_pattern.sub('', cleaned)
    
    # ç§»é™¤ç‰¹æ®Šè£…é¥°ç¬¦å·
    special_chars = ['ã‚', 'ã®', 'âœ¨', 'ğŸŒŸ', 'â­', 'ğŸ’«', 'ğŸ”¥', 'ğŸ’ª', 'ğŸ‘', 'â¤ï¸', 'ğŸ’™', 'ğŸ’š', 'ğŸ’›', 'ğŸ’œ', 'ğŸ§¡']
    for char in special_chars:
        cleaned = cleaned.replace(char, '')
    
    # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    
    # å¦‚æœæ¸…æ´—åä¸ºç©ºï¼Œè¿”å›åŸå§‹åç§°çš„å‰å‡ ä¸ªå­—ç¬¦
    if not cleaned:
        return original_name[:5] if len(original_name) > 5 else original_name
    
    return cleaned


def generate_episode_id(episode_type: EpisodeType, content: str) -> str:
    """
    ç”ŸæˆEpisodeå”¯ä¸€ID
    
    Args:
        episode_type: Episodeç±»å‹
        content: Episodeå†…å®¹
        
    Returns:
        str: å”¯ä¸€ID
    """
    import hashlib
    
    # ä½¿ç”¨ç±»å‹å’Œå†…å®¹çš„å“ˆå¸Œå€¼ç”ŸæˆID
    content_hash = hashlib.md5(f"{episode_type.value}:{content}".encode('utf-8')).hexdigest()
    return f"{episode_type.value}_{content_hash[:8]}"


def infer_relationship_type(context: str, group_name: str) -> RelationshipType:
    """
    æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­å…³ç³»ç±»å‹
    
    Args:
        context: å…³ç³»ä¸Šä¸‹æ–‡
        group_name: ç¾¤ç»„åç§°
        
    Returns:
        RelationshipType: æ¨æ–­çš„å…³ç³»ç±»å‹
    """
    # åŸºäºç¾¤ç»„åç§°çš„ç®€å•æ¨æ–­è§„åˆ™
    group_lower = group_name.lower()
    
    if any(keyword in group_lower for keyword in ['å·¥ä½œ', 'é¡¹ç›®', 'ç ”å‘', 'å¼€å‘', 'å›¢é˜Ÿ', 'team', 'work']):
        return RelationshipType.PROJECT_COLLABORATOR
    elif any(keyword in group_lower for keyword in ['æœ‹å‹', 'åŒå­¦', 'ç­çº§', 'friend', 'class']):
        return RelationshipType.FRIEND
    elif any(keyword in group_lower for keyword in ['å®¶åº­', 'å®¶äºº', 'family']):
        return RelationshipType.FAMILY
    else:
        return RelationshipType.COLLEAGUE  # é»˜è®¤ä¸ºåŒäº‹å…³ç³»