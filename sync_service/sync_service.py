#!/usr/bin/env python3
"""
The Archivist - Background Sync Service
Main entry point for the sync service that monitors Notion and updates the graph.
"""

import asyncio
import signal
import sys
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, Dict, Any

from loguru import logger

from config.settings import get_settings
from config.logging import setup_logging, LogExecutionTime
from core.notion_client import NotionExtractor
from core.graphiti_client import GraphitiClient
from .notion_scanner import NotionScanner
from .graph_updater import GraphUpdater
from .scheduler import SyncScheduler


class SyncService:
    """
    Main sync service that coordinates the entire sync process.
    """
    
    def __init__(self):
        self.settings = get_settings()
        self.running = False
        self.notion_client = None
        self.graph_client = None
        self.scanner = None
        self.updater = None
        self.scheduler = None
        self._last_full_sync_time = None
        
    async def initialize(self):
        """Initialize all components of the sync service."""
        logger.info("Initializing sync service...")
        
        # Initialize clients
        self.notion_client = NotionExtractor(
            api_key=self.settings.notion_token,
            rate_limit_per_second=self.settings.notion_rate_limit_per_second
        )
        
        self.graph_client = GraphitiClient(
            neo4j_uri=self.settings.neo4j_uri,
            neo4j_user=self.settings.neo4j_username,
            neo4j_password=self.settings.neo4j_password
        )
        
        # Initialize service components
        self.scanner = NotionScanner(self.notion_client)
        self.updater = GraphUpdater(self.graph_client, self.notion_client)
        self.scheduler = SyncScheduler(
            sync_interval_minutes=self.settings.sync_interval_minutes,
            sync_callback=self.run_sync_cycle
        )
        
        # Initialize graph client
        await self.graph_client.initialize()
        
        logger.info("Sync service initialized successfully")
    
    async def run_sync_cycle(self) -> bool:
        """
        Run a complete sync cycle.
        å†³å®šæ‰§è¡Œå…¨é‡åŒæ­¥æˆ–å¢é‡åŒæ­¥çš„ç­–ç•¥ï¼š
        - é¦–æ¬¡è¿è¡Œï¼šå…¨é‡åŒæ­¥
        - è·ç¦»ä¸Šæ¬¡å…¨é‡åŒæ­¥è¶…è¿‡3å¤©ï¼šå…¨é‡åŒæ­¥
        - åŒ—äº¬æ—¶é—´å‡Œæ™¨4ç‚¹å®šæ—¶å…¨é‡åŒæ­¥ï¼ˆè·ç¦»ä¸Šæ¬¡å…¨é‡åŒæ­¥è¶…è¿‡1å¤©ï¼‰
        - å…¶ä»–æƒ…å†µï¼šå¢é‡åŒæ­¥
        
        Returns:
            True if sync was successful, False otherwise
        """
        logger.info("Starting sync cycle...")
        
        try:
            with LogExecutionTime("sync_cycle"):
                # Check health of both services
                if not await self._health_check():
                    logger.error("Health check failed, skipping sync cycle")
                    return False
                
                # åˆ¤æ–­æ˜¯å¦éœ€è¦å…¨é‡åŒæ­¥
                should_do_full_sync = await self._should_do_full_sync()
                
                if should_do_full_sync:
                    logger.info("ğŸ”„ æ‰§è¡Œå…¨é‡åŒæ­¥ (æ¸…ç©ºæ•°æ®åº“åé‡æ–°æ„å»ºå›¾è°±)")
                    success = await self._run_full_sync()
                else:
                    logger.info("âš¡ æ‰§è¡Œå¢é‡åŒæ­¥")
                    success = await self._run_incremental_sync()
                
                if success:
                    # Update last sync time
                    await self._update_last_sync_time()
                    
                    # å¦‚æœæ˜¯å…¨é‡åŒæ­¥ï¼Œæ›´æ–°å…¨é‡åŒæ­¥æ—¶é—´
                    if should_do_full_sync:
                        await self._update_last_full_sync_time()
                    
                    logger.info("Sync cycle completed successfully")
                else:
                    logger.error("Sync cycle failed")
                
                return success
                
        except Exception as e:
            logger.exception(f"Sync cycle failed: {e}")
            return False
    
    async def _health_check(self) -> bool:
        """Check health of Notion API and Graph database."""
        try:
            notion_healthy = await self.notion_client.health_check()
            graph_healthy = await self.graph_client.health_check()
            
            if not notion_healthy:
                logger.error("Notion API health check failed")
            if not graph_healthy:
                logger.error("Graph database health check failed")
            
            return notion_healthy and graph_healthy
            
        except Exception as e:
            logger.exception(f"Health check failed: {e}")
            return False
    
    async def _get_last_sync_time(self) -> Optional[datetime]:
        """Get the last sync time from the graph database."""
        try:
            # Query for sync metadata
            query = """
            MATCH (meta:SyncMetadata)
            RETURN meta.last_sync_time as last_sync_time
            ORDER BY meta.last_sync_time DESC
            LIMIT 1
            """
            
            async with self.graph_client._driver.session() as session:
                result = await session.run(query)
                record = await result.single()
                if record:
                    return record["last_sync_time"]
            
            return None
            
        except Exception as e:
            logger.warning(f"Could not get last sync time: {e}")
            return None
    
    async def _update_last_sync_time(self):
        """Update the last sync time in the graph database."""
        try:
            query = """
            MERGE (meta:SyncMetadata {id: 'main'})
            SET meta.last_sync_time = datetime()
            """
            
            async with self.graph_client._driver.session() as session:
                await session.run(query)
            
        except Exception as e:
            logger.warning(f"Could not update last sync time: {e}")
    
    async def _get_last_full_sync_time(self) -> Optional[datetime]:
        """Get the last full sync time from the graph database."""
        try:
            query = """
            MATCH (meta:SyncMetadata {id: 'main'})
            RETURN meta.last_full_sync_time as last_full_sync_time
            """
            
            async with self.graph_client._driver.session() as session:
                result = await session.run(query)
                record = await result.single()
                if record and record["last_full_sync_time"]:
                    return record["last_full_sync_time"]
            
            return None
            
        except Exception as e:
            logger.warning(f"Could not get last full sync time: {e}")
            return None
    
    async def _update_last_full_sync_time(self):
        """Update the last full sync time in the graph database."""
        try:
            query = """
            MERGE (meta:SyncMetadata {id: 'main'})
            SET meta.last_full_sync_time = datetime()
            """
            
            async with self.graph_client._driver.session() as session:
                await session.run(query)
            
        except Exception as e:
            logger.warning(f"Could not update last full sync time: {e}")
    
    async def _should_do_full_sync(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œå…¨é‡åŒæ­¥"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¦–æ¬¡è¿è¡Œç¨‹åºï¼ˆæ£€æŸ¥Neo4jä¸­æ˜¯å¦æœ‰ä»»ä½•NotionPageï¼‰
        is_first_run = await self._is_first_run()
        if is_first_run:
            logger.info("ğŸ†• é¦–æ¬¡è¿è¡Œç¨‹åºï¼ŒNeo4jä¸­æ²¡æœ‰ä»»ä½•é¡µé¢æ•°æ®ï¼Œæ‰§è¡Œå…¨é‡åŒæ­¥")
            return True
        
        # è·å–ä¸Šæ¬¡å…¨é‡åŒæ­¥æ—¶é—´
        last_full_sync = await self._get_last_full_sync_time()
        
        if last_full_sync is None:
            logger.info("ğŸ†• æ²¡æœ‰å…¨é‡åŒæ­¥è®°å½•ï¼Œéœ€è¦å…¨é‡åŒæ­¥")
            return True
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡12å°æ—¶ (å¤„ç†Neo4j DateTimeç±»å‹å’Œæ—¶åŒºé—®é¢˜)
        if hasattr(last_full_sync, 'to_native'):
            # Neo4j DateTimeè½¬æ¢ä¸ºPython datetime
            last_full_sync_native = last_full_sync.to_native()
        else:
            last_full_sync_native = last_full_sync
        
        # ç¡®ä¿ä¸¤ä¸ªdatetimeå¯¹è±¡å…·æœ‰ç›¸åŒçš„æ—¶åŒºä¿¡æ¯
        from datetime import timezone
        now = datetime.now(timezone.utc)
        if last_full_sync_native.tzinfo is None:
            # å¦‚æœæ•°æ®åº“æ—¶é—´æ²¡æœ‰æ—¶åŒºï¼Œå‡è®¾æ˜¯UTC
            last_full_sync_native = last_full_sync_native.replace(tzinfo=timezone.utc)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å…¨é‡åŒæ­¥ï¼ˆ3å¤©ä¸€æ¬¡ï¼ŒåŒ—äº¬æ—¶é—´å‡Œæ™¨4ç‚¹ï¼‰
        days_since_last_full = (now - last_full_sync_native).total_seconds() / (24 * 3600)
        
        # å¦‚æœè·ç¦»ä¸Šæ¬¡å…¨é‡åŒæ­¥è¶…è¿‡3å¤©ï¼Œéœ€è¦å…¨é‡åŒæ­¥
        if days_since_last_full >= 3:
            logger.info(f"â° è·ç¦»ä¸Šæ¬¡å…¨é‡åŒæ­¥å·²è¿‡ {days_since_last_full:.1f} å¤©ï¼Œéœ€è¦å…¨é‡åŒæ­¥")
            return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒ—äº¬æ—¶é—´å‡Œæ™¨4ç‚¹ï¼ˆå…è®¸åœ¨4:00-4:30ä¹‹é—´æ‰§è¡Œï¼‰
        from datetime import timezone, timedelta
        beijing_tz = timezone(timedelta(hours=8))
        beijing_now = now.astimezone(beijing_tz)
        current_hour = beijing_now.hour
        current_minute = beijing_now.minute
        
        # å¦‚æœè·ç¦»ä¸Šæ¬¡å…¨é‡åŒæ­¥è¶…è¿‡1å¤©ï¼Œä¸”å½“å‰æ˜¯åŒ—äº¬æ—¶é—´å‡Œæ™¨4ç‚¹
        if days_since_last_full >= 1 and current_hour == 4 and current_minute < 30:
            logger.info(f"ğŸŒ™ åŒ—äº¬æ—¶é—´å‡Œæ™¨4ç‚¹å®šæ—¶å…¨é‡åŒæ­¥ (è·ç¦»ä¸Šæ¬¡ {days_since_last_full:.1f} å¤©)")
            return True
        
        logger.info(f"âš¡ è·ç¦»ä¸Šæ¬¡å…¨é‡åŒæ­¥ {days_since_last_full:.1f} å¤©ï¼Œæ‰§è¡Œå¢é‡åŒæ­¥")
        return False
    
    async def _is_first_run(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé¦–æ¬¡è¿è¡Œï¼ˆNeo4jä¸­æ˜¯å¦æœ‰ä»»ä½•NotionPageæ•°æ®ï¼‰"""
        try:
            query = "MATCH (n:NotionPage) RETURN count(n) as page_count LIMIT 1"
            async with self.graph_client._driver.session() as session:
                result = await session.run(query)
                record = await result.single()
                page_count = record["page_count"] if record else 0
                return page_count == 0
        except Exception as e:
            logger.warning(f"æ£€æŸ¥é¦–æ¬¡è¿è¡ŒçŠ¶æ€å¤±è´¥ï¼Œé»˜è®¤ä¸ºé¦–æ¬¡è¿è¡Œ: {e}")
            return True
    
    async def _run_full_sync(self) -> bool:
        """æ‰§è¡Œå…¨é‡åŒæ­¥ï¼Œå…ˆæ¸…ç©ºNeo4jæ•°æ®åé‡æ–°åŒæ­¥ï¼ˆä¸--force-full-syncé€»è¾‘ä¸€è‡´ï¼‰"""
        try:
            # 1. æ¸…ç©ºNeo4jæ•°æ®ï¼ˆä¸--force-full-syncä¿æŒä¸€è‡´ï¼‰
            logger.info("ğŸ§¹ æ¸…ç©ºNeo4jæ•°æ®...")
            clear_queries = [
                "MATCH (n:NotionPage) DETACH DELETE n",
                "MATCH (m:SyncMetadata) DELETE m"
            ]
            
            async with self.graph_client._driver.session() as session:
                for query in clear_queries:
                    result = await session.run(query)
                    summary = await result.consume()
                    logger.info(f"æ¸…ç†å®Œæˆï¼šåˆ é™¤äº† {summary.counters.nodes_deleted} ä¸ªèŠ‚ç‚¹")
            
            logger.info("ğŸ§¹ Neo4jæ•°æ®å·²æ¸…ç©º")
            
            # 2. è·å–æ‰€æœ‰Notioné¡µé¢
            logger.info("è·å–æ‰€æœ‰Notioné¡µé¢...")
            changed_pages = await self.scanner.scan_for_changes(None)  # Noneè¡¨ç¤ºå…¨é‡æ‰«æ
            
            # 3. æ›´æ–°å›¾æ•°æ®åº“ï¼ˆç”±äºå·²æ¸…ç©ºï¼Œè¿™é‡Œæ˜¯å…¨æ–°æ„å»ºï¼‰
            if changed_pages:
                logger.info(f"æ„å»º {len(changed_pages)} ä¸ªé¡µé¢åˆ°å›¾æ•°æ®åº“...")
                sync_report = await self.updater.update_graph(changed_pages)
                self._log_sync_results(sync_report)
            else:
                logger.info("æ²¡æœ‰å‘ç°ä»»ä½•é¡µé¢")
            
            return True
            
        except Exception as e:
            logger.exception(f"å…¨é‡åŒæ­¥å¤±è´¥: {e}")
            return False
    
    async def _run_incremental_sync(self) -> bool:
        """æ‰§è¡Œå¢é‡åŒæ­¥"""
        try:
            # Get last sync time
            last_sync_time = await self._get_last_sync_time()
            
            # Scan for changed pages
            changed_pages = await self.scanner.scan_for_changes(last_sync_time)
            
            if not changed_pages:
                logger.info("No changes detected, sync cycle complete")
                return True
            
            logger.info(f"Found {len(changed_pages)} pages to sync")
            
            # Update graph with changes
            sync_report = await self.updater.update_graph(changed_pages)
            
            # Log sync results
            self._log_sync_results(sync_report)
            
            return True
            
        except Exception as e:
            logger.exception(f"å¢é‡åŒæ­¥å¤±è´¥: {e}")
            return False
    
    async def _cleanup_deleted_pages(self, current_pages):
        """æ¸…ç†å·²åˆ é™¤çš„é¡µé¢"""
        try:
            # è·å–å½“å‰Notioné¡µé¢IDé›†åˆ
            current_page_ids = set(page.notion_id for page in current_pages)
            
            # è·å–Neo4jä¸­çš„æ‰€æœ‰é¡µé¢ID
            query = "MATCH (n:NotionPage) RETURN collect(n.notionId) as page_ids"
            async with self.graph_client._driver.session() as session:
                result = await session.run(query)
                record = await result.single()
                graph_page_ids = set(record["page_ids"] if record else [])
            
            # æ‰¾å‡ºéœ€è¦åˆ é™¤çš„é¡µé¢
            deleted_page_ids = graph_page_ids - current_page_ids
            
            if deleted_page_ids:
                logger.info(f"ğŸ—‘ï¸ å‘ç° {len(deleted_page_ids)} ä¸ªå·²åˆ é™¤é¡µé¢ï¼Œå¼€å§‹æ¸…ç†...")
                
                # ä»Neo4jåˆ é™¤
                delete_query = """
                MATCH (n:NotionPage) 
                WHERE n.notionId IN $page_ids
                DETACH DELETE n
                """
                
                async with self.graph_client._driver.session() as session:
                    result = await session.run(delete_query, page_ids=list(deleted_page_ids))
                    summary = await result.consume()
                    
                    logger.info(f"âœ… å·²ä»Neo4jåˆ é™¤ {summary.counters.nodes_deleted} ä¸ªå¤±æ•ˆé¡µé¢")
            else:
                logger.info("âœ… æ²¡æœ‰å‘ç°éœ€è¦åˆ é™¤çš„é¡µé¢")
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†åˆ é™¤é¡µé¢å¤±è´¥: {e}")
    
    def _log_sync_results(self, sync_report):
        """Log the results of the sync operation."""
        logger.info(f"Sync completed: {sync_report.status}")
        logger.info(f"Pages processed: {sync_report.pages_processed}")
        logger.info(f"Pages created: {sync_report.pages_created}")
        logger.info(f"Pages updated: {sync_report.pages_updated}")
        logger.info(f"Pages deleted: {sync_report.pages_deleted}")
        logger.info(f"Relationships created: {sync_report.relationships_created}")
        logger.info(f"Relationships updated: {sync_report.relationships_updated}")
        logger.info(f"Relationships deleted: {sync_report.relationships_deleted}")
        
        if sync_report.errors:
            logger.warning(f"Errors during sync: {len(sync_report.errors)}")
            for error in sync_report.errors[:5]:  # Log first 5 errors
                logger.warning(f"Sync error: {error}")
    
    async def run_manual_sync(self):
        """Run a manual sync cycle."""
        logger.info("Starting manual sync...")
        success = await self.run_sync_cycle()
        if success:
            logger.info("Manual sync completed successfully")
        else:
            logger.error("Manual sync failed")
        return success
    
    async def start(self):
        """Start the sync service."""
        if self.running:
            logger.warning("Sync service is already running")
            return
        
        logger.info("Starting sync service...")
        self.running = True
        
        # Start scheduler
        await self.scheduler.start()
        
        logger.info("Sync service started successfully")
        
        # Keep the service running
        try:
            while self.running:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            logger.info("Received interrupt signal, stopping...")
        finally:
            await self.stop()
    
    async def stop(self):
        """Stop the sync service."""
        if not self.running:
            return
        
        logger.info("Stopping sync service...")
        self.running = False
        
        # Stop scheduler
        if self.scheduler:
            await self.scheduler.stop()
        
        # Close clients
        if self.graph_client:
            await self.graph_client.close()
        
        logger.info("Sync service stopped")
    
    async def get_stats(self):
        """Get sync service statistics."""
        if not self.graph_client:
            return {"error": "Graph client not initialized"}
        
        try:
            stats = await self.graph_client.get_graph_stats()
            return stats.dict()
        except Exception as e:
            logger.error(f"Error getting stats: {e}")
            return {"error": str(e)}


async def main():
    """Main entry point for the sync service."""
    # Setup logging
    setup_logging()
    
    # Create sync service
    sync_service = SyncService()
    
    # Setup signal handlers
    def signal_handler(signum, frame):
        logger.info(f"Received signal {signum}, initiating shutdown...")
        asyncio.create_task(sync_service.stop())
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        # Initialize and start service
        await sync_service.initialize()
        await sync_service.start()
        
    except Exception as e:
        logger.exception(f"Fatal error in sync service: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())